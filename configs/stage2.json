{
  "use_processor": true,
  "out_dir": "./test",
  "checkpoint": "stage2-cnn-best",
  "record_file": "record.txt",
  "teacher_model": "ft-bert",
  "teacher_model_name_or_path": "test/bert-cnn-best",
  "student_model": "ms-cnn",
  "class_num": 2,
  "tokenizer": false,
  "seed": 42,
  "gpuid": "1",
  "task_name": "steganalysis",

  "Dataset": {
    "name": "tweet",
    "stego_file": "data/stego.txt",
    "cover_file": "data/cover.txt",
    "csv_dir": "data",
    "resplit": true,
    "split_ratio": 0.8,
    "save_cache": false,
    "overwrite_cache": true
  },
  "Training_with_Processor": {
    "num_train_epochs": 10,
    "learning_rate": 1e-4,
    "eval_and_save_steps": 100,
    "model_name_or_path": "prajjwal1/bert-tiny",
    "do_lower_case":true,
    "per_gpu_train_batch_size": 32,
    "per_gpu_eval_batch_size": 64,
    "n_gpu": 1,
    "max_steps": -1,
    "gradient_accumulation_steps": 1,
    "warmup_ratio": 0.06,
    "weight_decay": 0.01,
    "adam_epsilon": 1e-8,
    "max_grad_norm": 1.0,
    "logging_steps": -1,
    "evaluate_during_training": true,
    "save_only_best": true,
    "use_fixed_seq_length": true,
    "eval_all_checkpoints": true,
    "skip_evaluate_dev":false,
    "teacher_criteration":"KLDivLoss",
    "distil_T": 2,
    "distil_alpha": 0.95
  },
  "FineTuneBERT": {
    "criteration": "CrossEntropyLoss"
  },
  "MSCNN": {
    "embed_size":300,
    "filter_num": 100,
    "dropout_rate": 0.5,
    "criteration":"CrossEntropyLoss"
  },
  "MSBiRNN": {
    "embed_size":300,
    "hidden_size": 200,
    "num_layers": 1,
    "bidirectional": true,
    "criteration":"CrossEntropyLoss"
  }
}