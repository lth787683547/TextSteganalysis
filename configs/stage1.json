{
  "use_processor": true,
  "out_dir": "./test",
  "checkpoint": "stage1-best",
  "record_file": "record.txt",
  "model": "ft-bert",
  "class_num": 2,
  "tokenizer": false,
  "seed": 42,
  "gpuid": "1",
  "task_name": "steganalysis",
  "use_plm":true,

  "Dataset": {
    "name": "tweet",
    "stego_file": "data/stego.txt",
    "cover_file": "data/cover.txt",
    "csv_dir": "data",
    "resplit": true,
    "split_ratio": 0.8,
    "save_cache": false,
    "overwrite_cache": true
  },
  "Training_with_Processor": {
    "num_train_epochs": 100,
    "learning_rate": 5e-5,
    "eval_and_save_steps": 100,
    "model_name_or_path": "prajjwal1/bert-tiny",
    "do_lower_case":true,
    "per_gpu_train_batch_size": 32,
    "per_gpu_eval_batch_size": 32,
    "n_gpu": 1,
    "max_steps": -1,
    "gradient_accumulation_steps": 1,
    "warmup_ratio": 0.06,
    "weight_decay": 0.01,
    "adam_epsilon": 1e-8,
    "max_grad_norm": 1.0,
    "logging_steps": -1,
    "evaluate_during_training": true,
    "save_only_best": true,
    "use_fixed_seq_length": true,
    "eval_all_checkpoints": true,
    "skip_evaluate_dev":false
  },
  "FineTuneBERT": {
    "criteration": "CrossEntropyLoss"
  }
}